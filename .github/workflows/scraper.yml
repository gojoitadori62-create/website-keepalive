name: Keep Website Alive

on:
  schedule:
    # Run every 5 minutes
    - cron: '*/5 * * * *'
  # Allow manual triggers
  workflow_dispatch:

jobs:
  visit-website:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget unzip xvfb libnss3-dev libxss1 libasound2 libxrandr2 libatk1.0-0 libatk-bridge2.0-0 libdrm2 libgtk-3-0 libgbm1
    
    - name: Install Chrome
      run: |
        wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create screenshots directory
      run: mkdir -p screenshots
    
    - name: Visit website
      run: |
        # Start virtual display for headless Chrome
        export DISPLAY=:99
        Xvfb :99 -screen 0 1920x1080x16 &
        
        # Run the script
        python scraper.py
      continue-on-error: true  # Don't fail the workflow if there's an error
      
    - name: List files (for debugging)
      run: |
        ls -la
        ls -la screenshots/
      
    - name: Upload screenshots
      if: always()  # Always run this step even if previous steps failed
      uses: actions/upload-artifact@v4
      with:
        name: website-screenshots
        path: |
          screenshots/
          !.gitkeep
        retention-days: 7
